{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import huggingface_hub\n",
    "from huggingface_hub import InferenceClient\n",
    "import ast\n",
    "\n",
    "def get_searches(query):\n",
    "    load_dotenv()\n",
    "    API_KEY = os.getenv(\"API_KEY\")\n",
    "    query = query\n",
    "\n",
    "    params_related = {\"q\": query, \"api_key\": API_KEY, \"engine\": \"google\",\"nums\":200}\n",
    "    related_res = requests.get(\"https://serpapi.com/search\", params=params_related)\n",
    "\n",
    "    params_auto = {\"q\": query, \"api_key\": API_KEY, \"engine\": \"google_autocomplete\"}\n",
    "    auto_res = requests.get(\"https://serpapi.com/search\", params=params_auto)\n",
    "\n",
    "    related_searches = related_res.json().get(\"related_searches\", []) if related_res.status_code == 200 else []\n",
    "    autocomplete_suggestions = auto_res.json().get(\"suggestions\", []) if auto_res.status_code == 200 else []\n",
    "\n",
    "    context=[]\n",
    "    for i, item in enumerate(related_searches, 1):\n",
    "        if ((list(item.keys()))[1])=='query':\n",
    "            context.append(item['query'])\n",
    "\n",
    "    for i, item in enumerate(autocomplete_suggestions, len(related_searches) + 1):\n",
    "        context.append(item['value'])\n",
    "    return check_searches(context, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_searches(context, query):\n",
    "    apikey=os.getenv(\"apikey\")\n",
    "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "    client = InferenceClient(\n",
    "        api_key=apikey,\n",
    "        model=repo_id,\n",
    "        timeout=120,\n",
    "    )\n",
    "    query_template = \"\"\"Given the context: {context}\\n\n",
    "                        is to be filtered based on the given query:{query}. If the context: {context} is not related to {query},\\n\n",
    "                        do not return the context else return the context. Do not give any comments before or after just the context in a new line.\n",
    "                        The context:{context} is never going to be about movies or songs, its about investments or real life things. Think carefully before returning context: {context}\n",
    "                        Do not repeat any context all of them should be unique such that no keyword is repeated except for context:{context}\n",
    "                        Return the output in a single list seperated by commas not a string\"\"\"\n",
    "    query=query \n",
    "    prom = query_template.format(query=query, context=context)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prom},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\"}\n",
    "    ] \n",
    "    response = client.chat.completions.create(\n",
    "    model=repo_id,\n",
    "    messages=messages\n",
    "    )\n",
    "    return string_to_list(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string_input):\n",
    "    try:\n",
    "        return ast.literal_eval(string_input)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(\"Invalid input format\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=get_searches('Cars')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
